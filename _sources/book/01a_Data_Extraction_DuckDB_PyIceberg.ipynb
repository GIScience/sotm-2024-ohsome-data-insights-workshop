{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee2c20c-e467-4499-84c5-0d583cee77b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# DuckDB + PyIceberg: Data Extraction from *geo-sorted ohsome contributions* \n",
    "\n",
    ":::{note}\n",
    "1. Set the connection params and configure DuckDB.\n",
    "2. Download the data in 3 steps:\n",
    "    * Download data with PyIceberg.\n",
    "    * Fitler and process data with DuckDB.\n",
    "    * Export results into geopackage file with GeoPandas.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec70ad-bce1-4052-b151-23fe47fad942",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "Set connection params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554c5bc9-8962-44ed-96f8-fd34b3efe564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "s3_user = os.environ[\"S3_ACCESS_KEY_ID\"]  # add your user here\n",
    "s3_password = os.environ[\"S3_SECRET_ACCESS_KEY\"]  # add your password here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eccfe1-6b87-4640-a33a-3314252d0223",
   "metadata": {},
   "source": [
    "Configure DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e24802-8629-4648-afe5-d4c5f21403df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect(\n",
    "    config={\n",
    "        'threads': 8,\n",
    "        'max_memory': '8GB',\n",
    "        # 'enable_object_cache': True\n",
    "    }\n",
    ")\n",
    "con.install_extension(\"spatial\")\n",
    "con.load_extension(\"spatial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aebd24f-2bb2-43e7-9b50-9514caec4869",
   "metadata": {},
   "source": [
    "Set the connection params to Iceberg Rest Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016e60e-6286-40c0-a530-0ca9c0c9229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"pyiceberg[s3fs,duckdb,sql-sqlite,pyarrow]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825cd3dc-18d1-48fb-ad47-2945bb3a8c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog.rest import RestCatalog\n",
    "\n",
    "catalog = RestCatalog(\n",
    "    name=\"default\",\n",
    "    **{\n",
    "        \"uri\": \"https://sotm2024.iceberg.ohsome.org\",\n",
    "        \"s3.endpoint\": \"https://sotm2024.minio.heigit.org\",\n",
    "        \"py-io-impl\": \"pyiceberg.io.pyarrow.PyArrowFileIO\",\n",
    "        \"s3.access-key-id\": s3_user,\n",
    "        \"s3.secret-access-key\": s3_password,\n",
    "        \"s3.region\": \"eu-central-1\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed363ef-ee28-411e-9d56-501c1005beac",
   "metadata": {},
   "source": [
    "# Download data with PyIceberg table scan\n",
    "In this step we can already filter all OSM contributions by four major factors. We will perform more detailed filtering (e.g. for OSM tags values) later:\n",
    "* **status** (e.g. latest, historic or deleted OSM features)\n",
    "* **location** (using the bounding box coordinates of each OSM feature)\n",
    "* **geometry type** (e.g. for Polygons, Linestrings or Points)\n",
    "* **time** (e.g. the edit timestamp of each OSM contribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872da17b-f490-4a1a-8aec-09ad847db0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set iceberg table\n",
    "namespace = 'geo_sort'\n",
    "tablename = 'contributions'\n",
    "icebergtable = catalog.load_table((namespace, tablename))\n",
    "\n",
    "# Define status filter\n",
    "status = 'latest'\n",
    "\n",
    "# Define location filter\n",
    "bboxes = {\n",
    "    'heidelberg': (8.629761, 49.379556, 8.742371, 49.437890),\n",
    "    'nairobi': (36.650938, -1.444471, 37.103887, -1.163522),\n",
    "    'mannheim': (8.41416, 49.410362, 8.58999, 49.590489), \n",
    "    'berlin': (13.088345, 52.338271, 13.761161, 52.675509)\n",
    "}\n",
    "\n",
    "selected_region = 'nairobi'\n",
    "xmin, ymin, xmax, ymax = bboxes[selected_region]\n",
    "area_of_interest_file =f\"../data/{selected_region}.geojson\"\n",
    "area_of_interest_file = f\"https://raw.githubusercontent.com/GIScience/sotm-2024-ohsome-data-insights-workshop/main/data/{selected_region}.geojson\"\n",
    "\n",
    "# Define geometry type filter\n",
    "geometry_type = 'Polygon'\n",
    "\n",
    "# Define time filter (optional)\n",
    "min_timestamp = '2024-01-01T00:00:00'\n",
    "max_timestamp = '2024-06-01T00:00:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19916f1e-cb3b-417e-bff8-91831cb00f51",
   "metadata": {},
   "source": [
    "Furthermore, we define which attributes / columns this download should contain. Check out the [dataset description page](./README.md) to get an overview on all available columns.\n",
    "\n",
    "Usually you rarely want to extract all available columns as this would reduce speed of the data download. Here we are going to download the following information:\n",
    "* user_id\n",
    "* osm_id\n",
    "* osm_version\n",
    "* valid_from\n",
    "* tags\n",
    "* geometry "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da6409d-802d-4162-a6f6-df1ac74a6b50",
   "metadata": {},
   "source": [
    ":::{margin} Download speed matters only in this step.\n",
    "\n",
    "This is the only step in which we will download data from the server to our client (e.g. your laptop or jupyter notebook server). Internet connection and overall data size are the most common potential bottlenecks for this part of the analysis.</p>\n",
    "<p>We have optimized the structure for all tables in the <i>geo_sort</i> namespace to filter for status, geometry_type and location.\n",
    "    \n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab182ee-d069-46cb-a88d-e1a76f7ab1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download took 198.388 sec.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "icebergtable.scan(\n",
    "    row_filter=(\n",
    "        f\"status = '{status}' \"\n",
    "        f\"and geometry_type = '{geometry_type}' \"\n",
    "        f\"and (xmax >= {xmin} and xmin <= {xmax}) \"\n",
    "        f\"and (ymax >= {ymin} and ymin <= {ymax}) \"\n",
    "    ),\n",
    "    selected_fields=(\n",
    "        \"user_id\",\n",
    "        \"osm_id\",\n",
    "        \"osm_version\",\n",
    "        \"valid_from\",\n",
    "        \"tags\",\n",
    "        \"geometry\",\n",
    "    ),\n",
    ").to_duckdb('raw_osm_data',connection=con)\n",
    "\n",
    "download_time = round(time.time() - start_time, 3)\n",
    "print(f\"download took {download_time} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7965fc4-e82d-4972-8d5c-760fe45d3614",
   "metadata": {},
   "source": [
    "# Filter and process data with DuckDB\n",
    "Second, we use DuckDB to perform the more detailed filtering. In this step we can filter for:\n",
    "* **tags**\n",
    "* **location** (using the exact geometry of each OSM contribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2125907-3028-4e76-ae26-39ac7adf0f94",
   "metadata": {},
   "outputs": [
    {
     "ename": "IOException",
     "evalue": "IO Error: GDAL Error (4): Failed to open file https://raw.githubusercontent.com/GIScience/sotm-2024-ohsome-data-insights-workshop/main/data/nairobi.geojson: {\"exception_type\":\"IO\",\"exception_message\":\"Cannot open file \\\"https://raw.githubusercontent.com/GIScience/sotm-2024-ohsome-data-insights-workshop/main/data/nairobi.geojson\\\": No such file or directory\",\"errno\":\"2\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOException\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m\n\u001b[1;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mDROP TABLE IF EXISTS osm_data;\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mCREATE TABLE osm_data AS\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m;\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m processing_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessing took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessing_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sec.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIOException\u001b[0m: IO Error: GDAL Error (4): Failed to open file https://raw.githubusercontent.com/GIScience/sotm-2024-ohsome-data-insights-workshop/main/data/nairobi.geojson: {\"exception_type\":\"IO\",\"exception_message\":\"Cannot open file \\\"https://raw.githubusercontent.com/GIScience/sotm-2024-ohsome-data-insights-workshop/main/data/nairobi.geojson\\\": No such file or directory\",\"errno\":\"2\"}"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = f\"\"\"\n",
    "DROP TABLE IF EXISTS osm_data;\n",
    "CREATE TABLE osm_data AS\n",
    "(\n",
    "SELECT a.*  \n",
    "FROM\n",
    "    raw_osm_data as a,\n",
    "    st_read('{area_of_interest_file}') as aoi\n",
    "WHERE 1=1\n",
    "    and tags['building'][1] is not null\n",
    "    and tags['building'][1] != 'no'\n",
    "    -- spatial filtering part\n",
    "    and ST_Intersects(st_GeomFromText(a.geometry), aoi.geom)\n",
    ")\n",
    ";\n",
    "\"\"\"\n",
    "con.sql(query)\n",
    "\n",
    "processing_time = round(time.time() - start_time, 3)\n",
    "print(f\"processing took {processing_time} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8b5e7-41b7-4c3f-a901-3c5403dc4150",
   "metadata": {},
   "source": [
    "# Save data as GeoPackage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3500cf69-363b-452e-be63-0f969b536e5b",
   "metadata": {},
   "source": [
    "Show the structure of the data we have just downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d738f1c2-cbaf-49ce-9350-e6b28e2414b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────────┬────────────────────────────────────────────────────────────┬─────────┬─────────┬─────────┬─────────┐\n",
       "│ column_name │                        column_type                         │  null   │   key   │ default │  extra  │\n",
       "│   varchar   │                          varchar                           │ varchar │ varchar │ varchar │ varchar │\n",
       "├─────────────┼────────────────────────────────────────────────────────────┼─────────┼─────────┼─────────┼─────────┤\n",
       "│ user_id     │ INTEGER                                                    │ YES     │ NULL    │ NULL    │ NULL    │\n",
       "│ valid_from  │ TIMESTAMP                                                  │ YES     │ NULL    │ NULL    │ NULL    │\n",
       "│ osm_id      │ VARCHAR                                                    │ YES     │ NULL    │ NULL    │ NULL    │\n",
       "│ osm_version │ INTEGER                                                    │ YES     │ NULL    │ NULL    │ NULL    │\n",
       "│ tags        │ MAP(VARCHAR, VARCHAR)                                      │ YES     │ NULL    │ NULL    │ NULL    │\n",
       "│ bbox        │ STRUCT(xmin DOUBLE, ymin DOUBLE, xmax DOUBLE, ymax DOUBLE) │ YES     │ NULL    │ NULL    │ NULL    │\n",
       "│ geometry    │ VARCHAR                                                    │ YES     │ NULL    │ NULL    │ NULL    │\n",
       "└─────────────┴────────────────────────────────────────────────────────────┴─────────┴─────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "DESCRIBE\n",
    "FROM osm_data;\n",
    "\"\"\"\n",
    "con.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60155988-a105-4a04-a305-b635e6b41ce7",
   "metadata": {},
   "source": [
    "Inspect a few features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fc355bf-cf38-487d-9b80-5cc02b9edc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────┬────────────┬─────────┬─────────────┬──────────────────────┬─────────────────────────────────────┬──────────┐\n",
       "│ user_id │ valid_from │ osm_id  │ osm_version │         tags         │                bbox                 │ geometry │\n",
       "│  int32  │ timestamp  │ varchar │    int32    │ map(varchar, varch…  │ struct(xmin double, ymin double, …  │ varchar  │\n",
       "├─────────┴────────────┴─────────┴─────────────┴──────────────────────┴─────────────────────────────────────┴──────────┤\n",
       "│                                                        0 rows                                                        │\n",
       "└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM osm_data\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "con.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a670374-387b-4848-a295-cb2f2edc33b7",
   "metadata": {},
   "source": [
    "Count the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d070a68f-1615-4e5f-94ea-3cd837f2be4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────┐\n",
       "│ count_star() │\n",
       "│    int64     │\n",
       "├──────────────┤\n",
       "│            0 │\n",
       "└──────────────┘"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "SELECT count(*)\n",
    "FROM osm_data\n",
    "\"\"\"\n",
    "con.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c406784-9c12-41f9-9f1e-87b9c571cdc3",
   "metadata": {},
   "source": [
    "Export as GeoPackage via GeoPandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3648c939-7813-4be3-b1d0-b51d3fbad4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing took 0.109 sec.\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "start_time = time.time()\n",
    "query = f\"\"\"\n",
    "    SELECT osm_data.*\n",
    "    FROM\n",
    "        osm_data,\n",
    "        st_read('{area_of_interest_file}') as aoi\n",
    "    WHERE 1=1\n",
    "        and ST_Intersects(st_GeomFromText(osm_data.geometry), aoi.geom)\n",
    "\"\"\"\n",
    "df = con.sql(query).df()\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.GeoSeries.from_wkt(df['geometry'])\n",
    ").set_crs('epsg:4326')\n",
    "\n",
    "output_filename = f\"../data/{selected_region}_osm_data.gpkg\"\n",
    "gdf.to_file(output_filename, driver='GPKG')\n",
    "processing_time = round(time.time() - start_time, 3)\n",
    "print(f\"processing took {processing_time} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bf5649-9176-4e7f-83ac-752fc9e6faae",
   "metadata": {},
   "source": [
    "# Work with the data in QGIS\n",
    "Add your geopackage file in QGIS, e.g. via drag-and-drop or through file manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6087000-150b-4580-a3ed-a89236fee716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
